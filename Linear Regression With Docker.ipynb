{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02d6d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# this for inline visualization the \n",
    "# map or graph that we going to vizualize \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c803e",
   "metadata": {},
   "source": [
    "# Load the Data : Boston Housing Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c6bb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb9aab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check type of data \n",
    "type(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e72dedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31c80f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the description of the entier dataset \n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "413b2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(boston['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1dc4c3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "print(boston['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab9915b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "# the feature inforation of the dataset \n",
    "print(boston['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827aaaa",
   "metadata": {},
   "source": [
    "## Prepare the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67a0d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat the dataset \n",
    "# the DataFrame() - is used to created the entier dataset using the dataset which we load as whole \n",
    "#             but only we need some of the information so we have to choose the feature for the dataset \n",
    "#             thats what we going to do in this script \n",
    "dataset = pd.DataFrame(boston.data, columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20b15adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5969a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output feature that we going to predict \n",
    "dataset['price'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf43c8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d266e2",
   "metadata": {},
   "source": [
    "## Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ccef695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  price    506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "# check the whole set of information that the dataset we created \n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c2c8841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       price  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summrizing the stats of the data \n",
    "# this will be applied for all the numerical features and the categorical feature this will not apply\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c711be",
   "metadata": {},
   "source": [
    "### Checking the Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0039c332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "price      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1fa2cc",
   "metadata": {},
   "source": [
    "As result showing there is no null value in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47affb92",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898e6b4",
   "metadata": {},
   "source": [
    " #### About default -  corr() method details\n",
    " by default the method used here for the correlation is pearson<br>\n",
    " the peasron correlation is basically check the relationship between two features like x and y <br>\n",
    " the output pearson correlation is between -1 to 1<br>\n",
    " more towards the 1 is highly positivley correlated <br>\n",
    " more towards the -1 is highly negativly correlted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82e5e70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>-0.388305</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>-0.483725</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>-0.376955</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "price   -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
       "\n",
       "              DIS       RAD       TAX   PTRATIO         B     LSTAT     price  \n",
       "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  \n",
       "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  \n",
       "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  \n",
       "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  \n",
       "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  \n",
       "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  \n",
       "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  \n",
       "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  \n",
       "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  \n",
       "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  \n",
       "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  \n",
       "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  \n",
       "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  \n",
       "price    0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chcek the correaltion between the features\n",
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e6f57",
   "metadata": {},
   "source": [
    "There are 2 types of correlation we need to check <br>\n",
    "    1. correlation between independent feature<br>\n",
    "    2. correlation between independent and dependent feature <br>\n",
    "    \n",
    "(1) if there is high correlation between independent feature, in this time we can remove one of the independent feature<br>\n",
    "because that is what is called as multi-collinearity (if my 2 inpendent varible are verry highly correlated <br>\n",
    "(like correled like 95% or 96% percent, or else negtive correlation also possible), here we can drop one the feature<br>\n",
    "and just take the other one <br><br>\n",
    "\n",
    "(2) the other one is the correlation between the independent and dependent features <br>\n",
    "\n",
    "in comming step wil visulize the correlation and see how those are look "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let check with simple pairplot with seaborn\n",
    "import seaborn as sns \n",
    "sns.pairplot(dataset)\n",
    "\n",
    "# these graph we see hardly but if we have less number of feature thism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703225b5",
   "metadata": {},
   "source": [
    "## Analyzing The Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435baa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let check the relationship between the CRIMa and Price\n",
    "plt.scatter(dataset['CRIM'], dataset['price'])\n",
    "plt.xlabel('Crime Rate')\n",
    "plt.ylabel('price of the house')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc06f8",
   "metadata": {},
   "source": [
    "As the above chart we can see the inverse relationship between the feature Cime rate and price <br>\n",
    "when the crime rate getting huge the price decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb899625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let check another postive correaltion avaergae number of room and price\n",
    "plt.scatter(dataset['RM'], dataset['price'])\n",
    "plt.xlabel('Average Number of Rooms')\n",
    "plt.ylabel('price of the house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "sns.regplot(x='RM',y='price',data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c76db",
   "metadata": {},
   "source": [
    "The above chart is simllar to the scatter plot as we previously see but here we have simple linear line<br>\n",
    "show the rlationship in better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let see a negatively correlated feature\n",
    "sns.regplot(x='LSTAT',y='price',data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b164b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let see some of the feature not at all correlated \n",
    "sns.regplot(x='CHAS',y='price',data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad7d83",
   "metadata": {},
   "source": [
    "As we see above chart the both feature does not good correlation between them, that mean there is no linearity between \n",
    " the feature \n",
    " \n",
    " Linearity bassically mean when one feature increase or decrease the feature also should increas or decrease, if not there<br>\n",
    " is no linearity between the feature (the example is the above two features, those are doesn't have linear relationship <br> between them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da432b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='PTRATIO',y='price',data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd78ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Sepeartate Independent and Dependet variable/feature for further to develop the model \n",
    "x = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets chek the x and y \n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb44c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Here we going to do the train and test spit - which basically the proportion of split the dataset into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428856c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da545ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf05a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f16df",
   "metadata": {},
   "source": [
    "### Standard Scalling \n",
    "\n",
    "The process is to stanadradize the all the value into same kind of value<br>\n",
    "As we seeing the above datasets are having different different data value unit <br>\n",
    "but when we comming to gradient descent (converging algorithm)  we need to normalize or standardize those all the data <br>points to same sacle, then it will fast the calculation <br>\n",
    "\n",
    "this will be done based on standradize scalar \n",
    "\n",
    "### main aim in our linear regression to come near to the global minima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fec133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fae809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when ever try to apply to the test we dont use \"fit_transform\" but we only use \"transform\"\n",
    "# because we have to make sure that whatever information i have with respect to the trainting dataset and whatever \n",
    "# techiniques i have applied for the transforming it the same techniques need to be applied to the test data\n",
    "# this is done because to make sure that my model does not know much information about the test dataset\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d96ec",
   "metadata": {},
   "source": [
    "Here we going to pickle the model file (regression model file) so that we can further we can use this for deployment<br>\n",
    "So these projects will be deply using dockers and take the github action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037fb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impoprt pickle library, this very important library to do th pickling\n",
    "import pickle\n",
    "pickle.dump(scaler,open(\"scalling.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b317d2c",
   "metadata": {},
   "source": [
    "###  But any way i have to look at why we using fit_transform for scaler.x_train and only <br><br>scaler.transform for x_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8c6a95",
   "metadata": {},
   "source": [
    "### Why we standardize data\n",
    "\n",
    "internally we using graident descent, our main aim to come global minima\n",
    "to come to the global minima we have make sure that all <br>our independent feature\n",
    "units should be in the same scale because of that the convergence will happen Quickly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51b4d9",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ab3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b652660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the coefficient and intercepts\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9bfa08",
   "metadata": {},
   "source": [
    "For every feature there will be coefficient, here the changes of one unit that particular data point\n",
    "how that going to effect the dependent variable/ target variable linearly (positively or negtively)\n",
    "\n",
    "example\n",
    "\n",
    "if CRIM point increase by one point the price will reduce as -1.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on whcih parametters the model has been trained\n",
    "reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe2343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the prediction with the test data \n",
    "reg_pred = reg.predict(x_test)\n",
    "reg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982952c1",
   "metadata": {},
   "source": [
    "## check whether model is good or bad iwith various charts \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c4ae3",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e35ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot scatter plot for the prediction\n",
    "plt.scatter(y_test, reg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133b8bb",
   "metadata": {},
   "source": [
    "when the scatter plot shows the prediction and actual values of plotting linear then that is good prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction with residuals \n",
    "residuals = y_test - reg_pred\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting this residuals \n",
    "sns.displot(residuals,kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9aace",
   "metadata": {},
   "source": [
    "As we seeing this plot is look normal distribution but anyways there are some outliers can see on the right side\n",
    "\n",
    "\n",
    "Beyond this the residulas should be normally get as normal distribution, but actually we achieved it\n",
    "\n",
    "The range of the residual is 1 to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ef2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### scatter plot respect to orediction and residuals \n",
    "## Uniformly distributed \n",
    "plt.scatter(reg_pred, residuals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a08f7e",
   "metadata": {},
   "source": [
    "As you can see this scatter plot you seen that data points are uniformly scatter, there is not follwiing any kind kind <br>\n",
    "distribution or format and this means that the model is performing well  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a310",
   "metadata": {},
   "source": [
    "## Check the model with perfomance matrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_test,reg_pred))\n",
    "print(mean_absolute_error(y_test,reg_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test,reg_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8b7c7",
   "metadata": {},
   "source": [
    "The above result basically indicate how the model actualy performing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce29407",
   "metadata": {},
   "source": [
    "## R square and Adjuested R Square "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe774ce",
   "metadata": {},
   "source": [
    "These are also very important perfomance metrics, when ever we create linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006a6f0",
   "metadata": {},
   "source": [
    "Formula \n",
    "### R^2 = 1 - SSR/SST\n",
    "\n",
    "R^2 = Coefficient of Determination<br> SSR = sum of square of residuals <br> SST =  sum of square total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a238ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "score= r2_score(y_test,reg_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce604f",
   "metadata": {},
   "source": [
    "The more towards the score actually good for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff173d0",
   "metadata": {},
   "source": [
    "### Adjusted R2 = 1 - [(1-R2)*(n-1)/(n-k-1)]\n",
    "\n",
    "Where:\n",
    "<br><br>\n",
    "R2: The R2 of the model <br>\n",
    "n: The number of observations <br>\n",
    "k: The number of predictor variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefce0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar2 = 1 - (1 - score) * (len(y_test)-1) / (len(y_test) - x_test.shape[1]-1)\n",
    "print(ar2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701d205",
   "metadata": {},
   "source": [
    "# NOTE \n",
    "\n",
    "### Have to Look at all individual performance metrics and understand the math and the concept behind them\n",
    "### Also have to look at the differnt types of plots and make sure to understand the purpose of those plots and understand where to use those "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c2546",
   "metadata": {},
   "source": [
    "## New Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b91a08",
   "metadata": {},
   "source": [
    "Here we going to give the single data point from our dataset and check how the prediction can be done usin those data<br>\n",
    "When we giving data to the model prediction we have to give that as 2 dimensional,so let see how these can be achieved<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca32596",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc443a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let see how we can give the first data point and do the prediction \n",
    "# now changed the dimension to 2 dimension \n",
    "boston.data[0].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1485ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets transform the data points to same scale \n",
    "scaler.transform(boston.data[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but anywasy when ever we going to give the data point o the prediction the standard step should be followed\n",
    "# here we going do the scalling (we shiould make sure the data points are in the same types of value)\n",
    "reg.predict(scaler.transform(boston.data[0].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c01dd5",
   "metadata": {},
   "source": [
    "## Picking the model File For Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump(reg,open(\"regmodel.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ddee8",
   "metadata": {},
   "source": [
    "as first parameter to this we passing the model object \n",
    "then what name and where it shoul be created <br>\n",
    "the mode is \"wb (write byte)\": it will down all the content of the object inside this file <br><br>\n",
    "The pickle is serialized format file, so that it can deploy in and server and problem if you want<br>\n",
    "fo the prediction from the web application we can easily do it <br><br>\n",
    "\n",
    "All the information of the model is stored as serilialized format, so that we can load it again and use as the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg,open(\"regmodel.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a76136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pickle also can be loaded : now we have to read in \"read byte\" mode\n",
    "pickled_model = pickle.load(open('regmodel.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35698be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets predic with the pickled model \n",
    "pickled_model.predict(scaler.transform(boston.data[0].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c93336",
   "metadata": {},
   "source": [
    "Here we can see the result is same as we got from the model prediction for single data point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f96ef1",
   "metadata": {},
   "source": [
    "### Now we will focus on how to convert the entier project into and end-to-end project itself "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0fe021",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "### 1. Learn About what is CI CD pipline in deployment of the model \n",
    "### 2. Follow the industrial formate to do the deploment, now we following but learn more \n",
    "###     (Use git, create ci cd pipe line,use cloud to load and deploy model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47819be",
   "metadata": {},
   "source": [
    "#### if ypu didnt create file LICENSE,.gitignore, README no worries we can create those and <br><br>select the template from there in github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318cd91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
